{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing encoded data created in Linear Regression Model\n",
    "encoded_data = pd.read_csv(\"../data/encoded_data.csv\")\n",
    "encoded_data = encoded_data.drop(columns =['Platform_0', 'Platform_1',\n",
    "       'Platform_2', 'Platform_3', 'Platform_4', 'Platform_5', 'Platform_6',\n",
    "       'Platform_7', 'Genre_0', 'Genre_1', 'Genre_2', 'Genre_3', 'Genre_4',\n",
    "       'Genre_5', 'Genre_6', 'Genre_7', 'Genre_8', 'Genre_9', 'Genre_10',\n",
    "       'Genre_11',\"Price\",\"Console\", \"Name\", \"Game Title\", \"Platform LabelCode\", \"Genre LabelCode\", \"Publisher\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales',\n",
       "       'Global_Sales', 'Mean', 'Median'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test, Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(encoded_data.drop([\"Mean\"],axis=1), \n",
    "                                                    encoded_data[\"Mean\"], test_size=0.35, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[295  16]\n",
      " [109  30]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.95      0.83       311\n",
      "        True       0.65      0.22      0.32       139\n",
      "\n",
      "    accuracy                           0.72       450\n",
      "   macro avg       0.69      0.58      0.57       450\n",
      "weighted avg       0.71      0.72      0.67       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Analysis\n",
    "\n",
    "* False indicates if the game price falls above the average prices for all the games in the data set. \n",
    "\n",
    "* Confusion Matrix:  \n",
    "    In row 1, of the 311 false Mean values, 295 were predicted correctly, and 16 were predicted as true. In row 2, of the 138 true Mean values, 109 were predicted correctly and 30 were predected as false.  \n",
    "  \n",
    "* Classification Report:  \n",
    "    The test data percentage that gave us the best F1-Score and accuracy was 35%.  \n",
    "    Precision is intuitively the ability of the classifier not to label as positive a sample that is negative.  \n",
    "    Recall is intuitively the ability of the classifier to find all the positive samples.  \n",
    "    The F1-Score can be interpreted as a weighted harmonic mean of the precision and recall, where an F1-Score reaches its best value at 1 and worst score at 0.  \n",
    "    Support is the number of occurrences of each class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
